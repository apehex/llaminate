{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xXM7DoPpds1"
      },
      "source": [
        "## Import deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W24EKFXaO5yC",
        "outputId": "3a3a9760-f923-4053-fd10-067d6989af2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlable\n",
            "  Downloading mlable-0.6.1-py3-none-any.whl (19 kB)\n",
            "Collecting tokun\n",
            "  Downloading tokun-0.9.1-py3-none-any.whl (18 kB)\n",
            "Collecting llaminate\n",
            "  Downloading llaminate-0.3.7-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec[http]<=2024.5.0,>=2023.1.0 (from datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: tensorflow>=2.15 in /usr/local/lib/python3.10/dist-packages (from mlable) (2.15.0)\n",
            "Requirement already satisfied: tensorflow-datasets>=4.9 in /usr/local/lib/python3.10/dist-packages (from tokun) (4.9.6)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (4.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (5.9.5)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.5.1)\n",
            "Requirement already satisfied: etils[enp,epath,epy,etree]>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15->mlable) (0.43.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets>=4.9->tokun) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets>=4.9->tokun) (3.19.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.0.3)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets>=4.9->tokun) (0.16)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.2.2)\n",
            "Installing collected packages: xxhash, requests, pyarrow-hotfix, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets, mlable, tokun, llaminate\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.20.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.5.0 llaminate-0.3.7 mlable-0.6.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-hotfix-0.6 requests-2.32.3 tokun-0.9.1 xxhash-3.4.1 yarl-1.9.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets mlable tokun llaminate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdR0Yr-S3RqK",
        "outputId": "d66c372c-3fde-4f33-dfdf-dae78626978c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login # 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\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXU-Ebl2pddk"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import functools\n",
        "import itertools\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "\n",
        "import datasets as ds\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import mlable.data\n",
        "import mlable.metrics\n",
        "\n",
        "import tokun.data\n",
        "import tokun.evaluation\n",
        "import tokun.meta\n",
        "import tokun.model\n",
        "import tokun.pipeline\n",
        "\n",
        "import llaminate.model\n",
        "import llaminate.pipeline\n",
        "import llaminate.utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn1ywhSrpin9",
        "outputId": "99c1f371-bea7-4090-a266-aeaa65c9dbdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Setup the GPU / TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_LfBoYAQa4d"
      },
      "outputs": [],
      "source": [
        "# MIXED PRECISION #############################################################\n",
        "\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFIMfPmgQa0h",
        "outputId": "6a924f37-1989-4d85-e9c8-d587b3367303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 object at 0x7e434a74c460>\n"
          ]
        }
      ],
      "source": [
        "# DEVICES #####################################################################\n",
        "\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "\n",
        "CPU = tf.config.list_logical_devices('CPU')\n",
        "GPU = tf.config.list_logical_devices('GPU')\n",
        "TPU = tf.config.list_logical_devices('TPU')\n",
        "\n",
        "if TPU:\n",
        "    RESOLVER = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(RESOLVER)\n",
        "    tf.tpu.experimental.initialize_tpu_system(RESOLVER)\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.TPUStrategy(RESOLVER)\n",
        "elif GPU:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(GPU)\n",
        "else:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(CPU)\n",
        "\n",
        "print(DISTRIBUTION_STRATEGY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9066X5EOyAX"
      },
      "source": [
        "## Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFSPMtQaO1fu"
      },
      "outputs": [],
      "source": [
        "# TOGGLE ######################################################################\n",
        "\n",
        "IMPORT = False\n",
        "FREEZE = True # freeze tokun weights\n",
        "TRAINING = True\n",
        "DEBUG = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t1jfsJlM3SX"
      },
      "source": [
        "## Defining The Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z74MlibMWnu"
      },
      "outputs": [],
      "source": [
        "# MODEL PARAMETERS ############################################################\n",
        "\n",
        "N_SEQUENCE_AXIS = 1\n",
        "N_FEATURE_AXIS = -1\n",
        "\n",
        "N_LAYERS_NUM = 8\n",
        "N_HEADS_NUM = 4\n",
        "\n",
        "N_CACHE_DIM = 256 # 2048 in llama3-8B but tokun embeddings = 16 chr = 4 llama3 tokens\n",
        "N_EMBED_DIM = 256\n",
        "N_HIDDEN_DIM = 4 * N_EMBED_DIM\n",
        "N_HEAD_DIM = N_EMBED_DIM // N_HEADS_NUM\n",
        "\n",
        "LLAMINATE_PATH = 'llaminate.keras'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGN0D5Mqv7Vi"
      },
      "outputs": [],
      "source": [
        "# TOKENIZER PARAMETERS ########################################################\n",
        "\n",
        "TOKUN_DIM = [4, 16]\n",
        "TOKUN_FACTOR = math.prod(TOKUN_DIM) // 4\n",
        "TOKUN_VERSION = tokun.meta.version(units=TOKUN_DIM, axis=1)\n",
        "\n",
        "TOKUN_LABEL = '7.3'\n",
        "TOKUN_PATH = 'tokun.keras'\n",
        "TOKUN_URL = 'https://github.com/apehex/tokun/raw/main/models/{}/{}/{}.keras'.format(*TOKUN_VERSION, TOKUN_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2bgdk4P02n8"
      },
      "outputs": [],
      "source": [
        "# TRAINING PARAMETERS #########################################################\n",
        "\n",
        "N_BATCH_DIM = 128\n",
        "N_SAMPLE_DIM = N_CACHE_DIM * TOKUN_FACTOR\n",
        "\n",
        "N_EPOCHS = 8\n",
        "\n",
        "R_0, B_1, B_2 = (0.1 if IMPORT else 1.) * 0.001, 0.9, 0.99\n",
        "\n",
        "CLASS_WEIGHTS = {__c: 0.3 if __c == 0 else 1. for __c in range(256)} # there are 3 times more 0s than other bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm6y63XRBz07"
      },
      "outputs": [],
      "source": [
        "# DERIVED PARAMETERS ##########################################################\n",
        "\n",
        "DATETIME = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "LLAMINATE_VERSION = [str(N_LAYERS_NUM), str(N_HIDDEN_DIM)]\n",
        "LLAMINATE_LOGS_PATH = os.path.join('.logs/', *LLAMINATE_VERSION, DATETIME)\n",
        "LLAMINATE_MODEL_PATH = 'llaminate.keras'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEyFtkcFNGe4"
      },
      "source": [
        "## Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWxgap423z1a"
      },
      "outputs": [],
      "source": [
        "# META ########################################################################\n",
        "\n",
        "# TODO bigcode/the-stack\n",
        "# TODO ArmelR/stack-exchange-instruction\n",
        "\n",
        "DATASETS_META = {\n",
        "    'pt-wikipedia': {\n",
        "        'path': 'wikimedia/wikipedia',\n",
        "        'name': '20231101.en',\n",
        "        'train': 'train[:90%]',\n",
        "        'test': 'train[-10%:]',\n",
        "        'features': ['text'],},\n",
        "    'ft-retro-ascii-art': {\n",
        "        'path': 'jdpressman/retro-ascii-art-v1',\n",
        "        'name': None,\n",
        "        'train': 'train',\n",
        "        'test': 'validation',\n",
        "        'features': ['prompt', 'art_aic'],},\n",
        "    'ft-stack-exchange': {\n",
        "        'path': 'Alignment-Lab-AI/Stack-Exchange-April',\n",
        "        'name': None,\n",
        "        'train': 'train[:90%]',\n",
        "        'test': 'train[-10%:]',\n",
        "        'features': ['question', 'answer'],},\n",
        "    'ft-math': {\n",
        "        'path': 'hendrycks/competition_math',\n",
        "        'name': None,\n",
        "        'train': 'train',\n",
        "        'test': 'test',\n",
        "        'features': ['problem', 'solution'],},}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4d2a123c7f6d4fe99aca54e4470c13eb",
            "2b276862ad42496eb143f441dd3755c2",
            "f4bf44bee4c544a7a95b919b87ea3c3d",
            "51e1c5a5a95b4b6294d3cedfda051e39",
            "634156833821456db2499d8450f1f537",
            "13232dabc3b84748bd5c8cac0f48ef53",
            "76d3701aaa244fc9b921b829b3b3f90d",
            "1f0b3c3b0d5b491a8962a3a0f28cb587",
            "2aa3b26c28bc4806bd82c72ae5fab6ff",
            "3b8c8fdcdb9140fca95a083577f05008",
            "a2d5bfd54a7c4824a4188eef1b634d92",
            "3607441a33804f7f8e78cd2e50888904",
            "3f9dabe1a7564c4baf78a7f13c6345da",
            "98635e2ce2d54aa9b4d225c14937f78e",
            "642dd80e87424d2fb1592c378ae63c5a",
            "542a5ad1d6ca42da87125296866f1d15",
            "36537e75ee8a460fa9ed85559b551b3c",
            "bf26938a23514c04b8c79a2f20827cb3",
            "a481ef74949b44b6a2e850b8048c10c0",
            "63be29fde0ac417c9a385d53513c5042",
            "558533e3193c4f0d84edd6b7bca9a7c3",
            "fbc7c8090a1846bc81bc24795ae0343c",
            "4ac3be549b024ea3a8e3aa701d37df14",
            "6b93653318ed4927b1220722120b92d1",
            "c9f314b7681c4e6cbdb47d0346b69b32",
            "eebb6cf6f9cb4214ae10c734d62d276b",
            "38576e5d2edf40d5b9e8b5aaf2322e67",
            "5a98f3d8339c45979c58d5be4d4772aa",
            "be309f28c99e419886bd63613e5316e4",
            "4530b073813f479e8ecb7ae44f0308a4",
            "029112a4db41449b849a53ab7a2bf6fb",
            "97986a6470294541bdfd32789c16e5f3",
            "e22872a2c8e74b9b927c3d866f7f4229"
          ]
        },
        "id": "39aImJwK68wr",
        "outputId": "3c794e26-55b7-4071-c29f-5bd07bfadbd5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d2a123c7f6d4fe99aca54e4470c13eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3607441a33804f7f8e78cd2e50888904",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading dataset shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ac3be549b024ea3a8e3aa701d37df14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# DOWNLOAD ####################################################################\n",
        "\n",
        "DATASETS = {\n",
        "    __name: {\n",
        "        'train': ds.load_dataset(path=__args['path'], name=__args['name'], split=__args['train']).to_tf_dataset(shuffle=True, batch_size=None),\n",
        "        'test': ds.load_dataset(path=__args['path'], name=__args['name'], split=__args['test']).to_tf_dataset(shuffle=True, batch_size=None),}\n",
        "    for __name, __args in DATASETS_META.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovWpdtkifbgg"
      },
      "source": [
        "## Checking The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10Ret-lA4Emo"
      },
      "outputs": [],
      "source": [
        "# STATS #######################################################################\n",
        "\n",
        "STATS = {__n: {'min': 0, 'max': 0, 'mean': 0} for __n in DATASETS}\n",
        "\n",
        "for __name in DATASETS:\n",
        "    # sample each dataset\n",
        "    __m = DATASETS_META[__name]\n",
        "    __b = iter(DATASETS[__name]['train'])\n",
        "    __s = [next(__b) for _ in range(128)]\n",
        "    __l = [len(tf.strings.join(inputs=[__e[__f] for __f in __m['features']], separator='\\x1d').numpy()) for __e in __s]\n",
        "    # save the stats\n",
        "    STATS[__name]['min'] = min(__l)\n",
        "    STATS[__name]['max'] = max(__l)\n",
        "    STATS[__name]['mean'] = tf.reduce_mean(__l).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6fDVKYvBl2i",
        "outputId": "17aa7b2b-c59f-486e-e7fb-2ea04957251e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pt-wikipedia': {'min': 116, 'max': 27133, 'mean': 2931}, 'ft-retro-ascii-art': {'min': 3017, 'max': 3238, 'mean': 3146}, 'ft-stack-exchange': {'min': 289, 'max': 9503, 'mean': 1935}, 'ft-math': {'min': 100, 'max': 4771, 'mean': 740}}\n"
          ]
        }
      ],
      "source": [
        "print(STATS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5__iAHh41CZH"
      },
      "outputs": [],
      "source": [
        "__b = iter(DATASETS['ft-stack-exchange']['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKfqzqJ4Anv8",
        "outputId": "6cc1033d-8936-4ba7-92f3-808e295af142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b\"List files sorted according to specific line of contents\\n\\nI have a directory of files. There is a line in each file that says:\\n# order: N\\n\\nwhere N is an integer number. I want to list all files in the directory (or even include them in wrapper script) according to that N number. Is this possible from a bash command-line?\\n\\n\\n\\x1dWith zsh, you can define a glob sorting order based on the content of those lines with:\\nbyOrder() REPLY=$(grep '^# order:' < $REPLY)\\n\\nand then use it for example with:\\nprintf '%s\\\\n' *(.no+byOrder)\\n\\nor\\nsorted_file_list=(*(.no+byOrder))\\n\\n(also adding a . to the glob qualifier to only consider regular files (not directories, fifos, symlinks...)).\\n\">"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "__s = next(__b)\n",
        "tf.strings.join(inputs=[__s['question'], __s['answer']], separator='\\x1d')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cheN52OEchs"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCMihca3F2yQ"
      },
      "outputs": [],
      "source": [
        "# ITERATE #####################################################################\n",
        "\n",
        "for __name in DATASETS:\n",
        "    # specialized preprocessing fn\n",
        "    __preprocess = functools.partial(llaminate.pipeline.preprocess, batch_dim=N_BATCH_DIM, token_dim=math.prod(TOKUN_DIM), embed_dim=N_EMBED_DIM, sample_dim=N_SAMPLE_DIM, features=DATASETS_META[__name]['features'], weight=True)\n",
        "    # preprocess datasets\n",
        "    DATASETS[__name]['train'] = DATASETS[__name]['train'].batch(N_BATCH_DIM, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).map(__preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    DATASETS[__name]['test'] = DATASETS[__name]['test'].batch(N_BATCH_DIM, drop_remainder=True, num_parallel_calls=tf.data.AUTOTUNE).map(__preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxz2uQx-g5SR"
      },
      "outputs": [],
      "source": [
        "# CONCATENATE #################################################################\n",
        "\n",
        "DATASET_TRAIN = functools.reduce(lambda __l, __r: __l.concatenate(__r), [DATASETS[__n]['train'] for __n in (set(DATASETS.keys()) - {'ft-retro-ascii-art'})]) # - {'pt-wikipedia'}\n",
        "DATASET_TEST = functools.reduce(lambda __l, __r: __l.concatenate(__r), [DATASETS[__n]['test'] for __n in (set(DATASETS.keys()) - {'ft-retro-ascii-art'})]) # - {'pt-wikipedia'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJFgVaASv0bY",
        "outputId": "2b190586-e3ee-48dd-e3eb-dc65990dec5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(TensorSpec(shape=(128, 16384), dtype=tf.uint8, name=None), TensorSpec(shape=(128, 16384, 256), dtype=tf.float32, name=None), TensorSpec(shape=(128, 16384), dtype=tf.float32, name=None))\n",
            "(TensorSpec(shape=(128, 16384), dtype=tf.uint8, name=None), TensorSpec(shape=(128, 16384, 256), dtype=tf.float32, name=None), TensorSpec(shape=(128, 16384), dtype=tf.float32, name=None))\n"
          ]
        }
      ],
      "source": [
        "# CHECK DATASET ###############################################################\n",
        "\n",
        "print(DATASET_TRAIN.element_spec)\n",
        "print(DATASET_TEST.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RyKbfSgZOrB",
        "outputId": "9dd15394-623b-4280-a239-477918475928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train: 73,681 samples\n",
            "test:  8,222 samples\n"
          ]
        }
      ],
      "source": [
        "print('train: {:,} samples'.format(DATASET_TRAIN.cardinality().numpy()))\n",
        "print('test:  {:,} samples'.format(DATASET_TEST.cardinality().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFehgkiDwBI2"
      },
      "source": [
        "## Load The Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfIZb86Fg0dQ",
        "outputId": "3a2cb727-1315-4e84-c0a0-9f3475e9c9da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tokun.keras', <http.client.HTTPMessage at 0x7e39802d9ea0>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DOWNLOAD ####################################################################\n",
        "\n",
        "urllib.request.urlretrieve(TOKUN_URL, TOKUN_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39n2JmXG6yv"
      },
      "source": [
        "## Initializing The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "130LK_GQv9X9"
      },
      "outputs": [],
      "source": [
        "# DEBUG MODEL #################################################################\n",
        "\n",
        "class DebugModel(tf.keras.Sequential):\n",
        "    def __init__(self, **kwargs) -> None:\n",
        "        super(DebugModel, self).__init__(\n",
        "            layers=[\n",
        "                tf.keras.layers.Embedding(\n",
        "                    input_dim=N_EMBED_DIM,\n",
        "                    output_dim=N_EMBED_DIM,\n",
        "                    embeddings_initializer='glorot_uniform',\n",
        "                    name='embed-1')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzD3vE7ZlB-Z"
      },
      "outputs": [],
      "source": [
        "# OVERALL SCOPE ###############################################################\n",
        "\n",
        "with DISTRIBUTION_STRATEGY.scope():\n",
        "    # TOKENIZER ###############################################################\n",
        "    TOKUN = tf.keras.models.load_model(TOKUN_PATH, compile=False)\n",
        "    TOKUN.trainable = not FREEZE # freeze the weights\n",
        "\n",
        "    # METRICS #################################################################\n",
        "    byte_accuracy = mlable.metrics.CategoricalGroupAccuracy(group=1, name='byte_accuracy')\n",
        "    character_accuracy = mlable.metrics.CategoricalGroupAccuracy(group=4, name='character_accuracy')\n",
        "    token_accuracy = mlable.metrics.CategoricalGroupAccuracy(group=math.prod(TOKUN_DIM), name='token_accuracy')\n",
        "\n",
        "    # WEIGHTS #################################################################\n",
        "    if IMPORT and os.path.isfile(LLAMINATE_MODEL_PATH):\n",
        "        LLAMINATE = tf.keras.models.load_model(LLAMINATE_MODEL_PATH, compile=False)\n",
        "    else:\n",
        "        LLAMINATE = llaminate.model.Transformer(num_layers=N_LAYERS_NUM, num_heads=N_HEADS_NUM, cache_dim=N_CACHE_DIM, embed_dim=N_EMBED_DIM, head_dim=N_HEAD_DIM, hidden_dim=N_HIDDEN_DIM)\n",
        "\n",
        "    # INIT ####################################################################\n",
        "    LLAMINATE.set_tokenizer(encoder=TOKUN._encoder, decoder=TOKUN._decoder)\n",
        "    # simpler model to debug\n",
        "    if DEBUG: LLAMINATE = DebugModel()\n",
        "\n",
        "    # INPUT ###################################################################\n",
        "    __input = tf.keras.Input(shape=(4 * TOKUN_FACTOR * N_CACHE_DIM,), batch_size=N_BATCH_DIM)\n",
        "    LLAMINATE = tf.keras.models.Model(__input, LLAMINATE(__input))\n",
        "\n",
        "    # COMPILE #################################################################\n",
        "    LLAMINATE.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=R_0, beta_1=B_1, beta_2=B_2),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0., axis=-1, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name='cce_loss'),\n",
        "        weighted_metrics=[byte_accuracy, character_accuracy, token_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLQ0A3mAiVQ7"
      },
      "outputs": [],
      "source": [
        "# INSPECT #####################################################################\n",
        "\n",
        "__b = iter(DATASET_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O08Up69-i5DL",
        "outputId": "b47e6e5a-f25f-4ce7-fa9d-cfb9ed00f93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 16384)\n",
            "(128, 16384, 256)\n",
            "(128, 16384)\n",
            "(128, 16384, 256)\n"
          ]
        }
      ],
      "source": [
        "__x, __y, __m = next(__b)\n",
        "print(__x.shape)\n",
        "print(__y.shape)\n",
        "print(__m.shape)\n",
        "print(LLAMINATE(__x, training=True).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBBF4QpNVHtF",
        "outputId": "f7a01525-23e0-4ce5-a620-bb303fddd6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"auto_encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  1377792   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  1382656   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2760448 (10.53 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 2760448 (10.53 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "TOKUN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz1lRnWtMSUm",
        "outputId": "8fb59cdc-8127-4f56-914c-b5367bddefec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(16, 16384)]             0         \n",
            "                                                                 \n",
            " transformer (Transformer)   (16, 16384, 256)          11157760  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11157760 (42.56 MB)\n",
            "Trainable params: 8397312 (32.03 MB)\n",
            "Non-trainable params: 2760448 (10.53 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LLAMINATE.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRkNkXthBwar"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "beTpALmzFdu1",
        "outputId": "163639fd-a211-4d8a-885f-d214bc3d196c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "28566/28567 [============================>.] - ETA: 0s - loss: 0.7223 - byte_accuracy: 0.7704 - character_accuracy: 0.3733 - token_accuracy: 0.0000e+00"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 228536 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3175 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 0.81156, saving model to llaminate.keras\n",
            "28567/28567 [==============================] - 20983s 733ms/step - loss: 0.7223 - byte_accuracy: 0.7704 - character_accuracy: 0.3733 - token_accuracy: 0.0000e+00 - val_loss: 0.8116 - val_byte_accuracy: 0.7938 - val_character_accuracy: 0.4534 - val_token_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# TRAIN #######################################################################\n",
        "\n",
        "if TRAINING:\n",
        "    with DISTRIBUTION_STRATEGY.scope():\n",
        "        # callbacks\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(LLAMINATE_MODEL_PATH, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=LLAMINATE_LOGS_PATH)\n",
        "        # model fitting\n",
        "        TRAINING_HISTORY = LLAMINATE.fit(\n",
        "            x=DATASETS['ft-stack-exchange']['train'].prefetch(tf.data.AUTOTUNE),\n",
        "            batch_size=None,\n",
        "            epochs=N_EPOCHS,\n",
        "            validation_split=None,\n",
        "            validation_data=DATASETS['ft-stack-exchange']['test'].prefetch(tf.data.AUTOTUNE),\n",
        "            validation_freq=list(range(1, N_EPOCHS + 1, 1)),\n",
        "            class_weight=CLASS_WEIGHTS,\n",
        "            verbose=1,\n",
        "            callbacks=[cp_callback, tb_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHtROW1K1R7c"
      },
      "source": [
        "## Dataviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EiRVgG-oSfb7"
      },
      "outputs": [],
      "source": [
        "# DATA ########################################################################\n",
        "\n",
        "SAMPLES = [\n",
        "    \"\"\"위키백과, 우리 모두의 백과사전.\\nt-분포 확률적 임베딩(t-SNE)은 데이터의 차원 축소에 사용되는 기계 학습 알고리즘 중 하나로, 2002년 샘 로이스Sam Rowise와 제프리 힌튼에 의해 개발되었다.[1] t-SNE는 비선형 차원 축소 기법으로, 고차원 데이터를 특히 2, 3차원 등으로 줄여 가시화하는데에 유용하게 사용된다. 구체적으로 t-SNE는 비슷한 데이터는 근접한 2, 3차원의 지점으로, 다른 데이터는 멀리 떨어진 지점으로 맵핑한다.\"\"\",\n",
        "    \"\"\"class Encoder(tf.keras.models.Model):\\n    def __init__(self, depth: int, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, attention: bool=False, **kwargs) -> None:\\n        super(Encoder, self).__init__(**kwargs)\\n        self._encoder = tf.keras.Sequential([\\n            tf.keras.Input(shape=(encoding_dim,), batch_size=batch_dim, name='input'), # (B * G ^ D, U)\\n            tf.keras.layers.Dense(units=embedding_dim, activation=None, use_bias=False, kernel_initializer='glorot_uniform', bias_initializer=None, name='embed-1'),] # (B * G ^ D, U) => (B * G ^ D, E)\\n            + [tokun.layers.TokenizeBlock(left_axis=-2, right_axis=-1, token_dim=token_dim, latent_dim=latent_dim, attention=attention, name='tokenize' + (__i + 1) * '-4') for __i in range(depth)]) # (B * G ^ i, E) => (B * G ^ (i-1), E)\\n\\n    def call(self, x: tf.Tensor) -> tf.Tensor:\\n        return self._encoder(x)\\n\"\"\",\n",
        "    \"\"\"class AutoEncoder(tf.keras.models.Model):\\n    def __init__(self, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, **kwargs) -> None:\\n        super(AutoEncoder, self).__init__(**kwargs)\\n        self._encoder = Encoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n        self._decoder = Decoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n\\n    def call(self, x: tf.Tensor) -> tf.Tensor:\\n        return self._decoder(self._encoder(x))\"\"\",\n",
        "    \"\"\"class AutoEncoder(tf.keras.models.Model):\\n  def __init__(self, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, **kwargs) -> None:\\n    super(AutoEncoder, self).__init__(**kwargs)\\n    self._encoder = Encoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n    self._decoder = Decoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n\\n  def call(self, x: tf.Tensor) -> tf.Tensor:\\n    return self._decoder(self._encoder(x))\"\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8naQsR7i8iea"
      },
      "outputs": [],
      "source": [
        "# CACHE #######################################################################\n",
        "\n",
        "__cache = llaminate.utils.create_cache(batch_dim=N_BATCH_DIM, cache_dim=N_CACHE_DIM, head_dim=N_HEAD_DIM, num_layers=N_LAYERS_NUM, num_heads=N_HEADS_NUM)\n",
        "__step = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HubWVf_L_Frh"
      },
      "outputs": [],
      "source": [
        "# PREPROCESS ##################################################################\n",
        "\n",
        "__prompt = \"\"\"Skynet is an artificial neural network-based conscious group mind and artificial general superintelligence system that serves as the antagonistic force of the Terminator franchise.\"\"\"\n",
        "__inputs = tokun.pipeline.preprocess(text=__prompt, token_size=4 * N_SAMPLE_DIM, expand=N_SEQUENCE_AXIS * [1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pt7OdZw22vGM",
        "outputId": "bcae2a21-7986-42d9-c3eb-f952ae37cb47"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\x1e!\\xa0ÄD𐀀𐀥ô \\x96𐂷=G\\x00\\x00\\x00\\x02!`ªD𐃐𐀥· \\x96𐂷=p\\x1e\\xa0\\x00\\x02~`ªD𐃐𐀍· \\x96𐂷=p\\x1e\\x00\\x00\\x02\\x02\\xa0ªD𐀀𐀍·h\\x96𐂷=ö\\x1et\\x00\\x02~`ªD𐃐𐀍·\\x1b\\x96𐂷=pß\\x9a \\x02Õ`ª\\uf744\\U0001007e𐀍·h\\x80𐂷=p\\x00\\x9a\\x00\\x02\\x00\\x00ª\\uf744\\U0001007e𐀥·h\\x96𐂷=pnt\\x00Ç~`ªD\\U0001007e𐀥· Ò𐂷ªpn\\x9aÄ\\x02Õ`ªD𐀀𐀥\\r \\x96𐂷\\xa0öß\\x00\\x00\\x02!\\x00ªD\\U0001007e𐀥·hÒ𐂷=p\\x00t\\x00\\x02\\x02\\x00ªD𐀀𐀍· \\x96𐂷\\xa0pß\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aed2\\U0003b809\\U000352bd\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aed2\\U00035197𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aed2𫣄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aebb𥇄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aed2𥇄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aed2𥇄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aebb𥇄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aebb𥇄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\U0003aebb𥇄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀\\x00\\x00\\x00\\x00\\x00껒𥷄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀\\x00\\x00\\x00\\x00\\x00꺻𥷄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄𥊽\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀\\x00\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶗�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶗�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀\\x00\\x00\\x00\\x00\\x00껒𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀\\x00\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠒀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠒀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠒀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠒀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𥶀�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𥷄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00꺻𠓄�\\x00\\x00\\x00\\x00\\x00\\x00\\x00𐀀𐀀\\x00\\x00\\x00\\x00껒𠓄�'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PREDICT #####################################################################\n",
        "\n",
        "__predictions = LLAMINATE(inputs=__inputs, training=False, mask=None)\n",
        "tokun.pipeline.postprocess(__predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tm0qRLA9r7zL"
      },
      "outputs": [],
      "source": [
        "__batch = iter(DATASETS['ft-stack-exchange']['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzM21G9YsIT7"
      },
      "outputs": [],
      "source": [
        "__x, __y, __m = next(__batch)\n",
        "__p = LLAMINATE(inputs=__x, training=True, mask=None)\n",
        "\n",
        "__xt = tokun.pipeline.postprocess(__x, onehot=False)\n",
        "__yt = tokun.pipeline.postprocess(__y)\n",
        "__yp = tokun.pipeline.postprocess(__p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkpSSNd8mhRz"
      },
      "outputs": [],
      "source": [
        "print(tokun.evaluation.compare(__yt, __yp))\n",
        "print(__yt)\n",
        "print(__yp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWmXaJzjhPaR"
      },
      "outputs": [],
      "source": [
        "tf.argmax(LLAMINATE._decoder(LLAMINATE._encoder(__x[:, :128])), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPRq7KOzkAly"
      },
      "outputs": [],
      "source": [
        "__x[:, :128]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgt0SQDbaopC"
      },
      "source": [
        "## Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eJmv4xjnTH4t"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir .logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "029112a4db41449b849a53ab7a2bf6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13232dabc3b84748bd5c8cac0f48ef53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f0b3c3b0d5b491a8962a3a0f28cb587": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa3b26c28bc4806bd82c72ae5fab6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b276862ad42496eb143f441dd3755c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13232dabc3b84748bd5c8cac0f48ef53",
            "placeholder": "​",
            "style": "IPY_MODEL_76d3701aaa244fc9b921b829b3b3f90d",
            "value": "Resolving data files: 100%"
          }
        },
        "3607441a33804f7f8e78cd2e50888904": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f9dabe1a7564c4baf78a7f13c6345da",
              "IPY_MODEL_98635e2ce2d54aa9b4d225c14937f78e",
              "IPY_MODEL_642dd80e87424d2fb1592c378ae63c5a"
            ],
            "layout": "IPY_MODEL_542a5ad1d6ca42da87125296866f1d15"
          }
        },
        "36537e75ee8a460fa9ed85559b551b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38576e5d2edf40d5b9e8b5aaf2322e67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8c8fdcdb9140fca95a083577f05008": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9dabe1a7564c4baf78a7f13c6345da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36537e75ee8a460fa9ed85559b551b3c",
            "placeholder": "​",
            "style": "IPY_MODEL_bf26938a23514c04b8c79a2f20827cb3",
            "value": "Loading dataset shards: 100%"
          }
        },
        "4530b073813f479e8ecb7ae44f0308a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac3be549b024ea3a8e3aa701d37df14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b93653318ed4927b1220722120b92d1",
              "IPY_MODEL_c9f314b7681c4e6cbdb47d0346b69b32",
              "IPY_MODEL_eebb6cf6f9cb4214ae10c734d62d276b"
            ],
            "layout": "IPY_MODEL_38576e5d2edf40d5b9e8b5aaf2322e67"
          }
        },
        "4d2a123c7f6d4fe99aca54e4470c13eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b276862ad42496eb143f441dd3755c2",
              "IPY_MODEL_f4bf44bee4c544a7a95b919b87ea3c3d",
              "IPY_MODEL_51e1c5a5a95b4b6294d3cedfda051e39"
            ],
            "layout": "IPY_MODEL_634156833821456db2499d8450f1f537"
          }
        },
        "51e1c5a5a95b4b6294d3cedfda051e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b8c8fdcdb9140fca95a083577f05008",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d5bfd54a7c4824a4188eef1b634d92",
            "value": " 41/41 [00:00&lt;00:00, 72.28it/s]"
          }
        },
        "542a5ad1d6ca42da87125296866f1d15": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558533e3193c4f0d84edd6b7bca9a7c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a98f3d8339c45979c58d5be4d4772aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634156833821456db2499d8450f1f537": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63be29fde0ac417c9a385d53513c5042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "642dd80e87424d2fb1592c378ae63c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_558533e3193c4f0d84edd6b7bca9a7c3",
            "placeholder": "​",
            "style": "IPY_MODEL_fbc7c8090a1846bc81bc24795ae0343c",
            "value": " 33/33 [00:00&lt;00:00, 418.99it/s]"
          }
        },
        "6b93653318ed4927b1220722120b92d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a98f3d8339c45979c58d5be4d4772aa",
            "placeholder": "​",
            "style": "IPY_MODEL_be309f28c99e419886bd63613e5316e4",
            "value": "Resolving data files: 100%"
          }
        },
        "76d3701aaa244fc9b921b829b3b3f90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97986a6470294541bdfd32789c16e5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98635e2ce2d54aa9b4d225c14937f78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a481ef74949b44b6a2e850b8048c10c0",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63be29fde0ac417c9a385d53513c5042",
            "value": 33
          }
        },
        "a2d5bfd54a7c4824a4188eef1b634d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a481ef74949b44b6a2e850b8048c10c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be309f28c99e419886bd63613e5316e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf26938a23514c04b8c79a2f20827cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9f314b7681c4e6cbdb47d0346b69b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4530b073813f479e8ecb7ae44f0308a4",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_029112a4db41449b849a53ab7a2bf6fb",
            "value": 41
          }
        },
        "e22872a2c8e74b9b927c3d866f7f4229": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eebb6cf6f9cb4214ae10c734d62d276b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97986a6470294541bdfd32789c16e5f3",
            "placeholder": "​",
            "style": "IPY_MODEL_e22872a2c8e74b9b927c3d866f7f4229",
            "value": " 41/41 [00:00&lt;00:00, 55.86it/s]"
          }
        },
        "f4bf44bee4c544a7a95b919b87ea3c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f0b3c3b0d5b491a8962a3a0f28cb587",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2aa3b26c28bc4806bd82c72ae5fab6ff",
            "value": 41
          }
        },
        "fbc7c8090a1846bc81bc24795ae0343c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}