{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xXM7DoPpds1"
      },
      "source": [
        "## Import deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W24EKFXaO5yC",
        "outputId": "838e2043-6e75-4f24-a70a-8ef3d46d46b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: mlable in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: tokun in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: llaminate in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: tensorflow>=2.15 in /usr/local/lib/python3.10/dist-packages (from mlable) (2.15.0)\n",
            "Requirement already satisfied: tensorflow-datasets>=4.9 in /usr/local/lib/python3.10/dist-packages (from tokun) (4.9.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (4.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (5.9.5)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (0.5.1)\n",
            "Requirement already satisfied: etils[enp,epath,epy,etree]>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.9->tokun) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15->mlable) (0.43.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets>=4.9->tokun) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets>=4.9->tokun) (3.19.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.0.3)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets>=4.9->tokun) (0.16)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets mlable tokun llaminate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdR0Yr-S3RqK",
        "outputId": "692c7f77-0d57-4ed9-c2b2-6987da59cd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXU-Ebl2pddk"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import functools\n",
        "import itertools\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "\n",
        "import datasets as ds\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import mlable.data\n",
        "import mlable.io\n",
        "import mlable.metrics\n",
        "import mlable.optimizers\n",
        "\n",
        "import tokun.data\n",
        "import tokun.evaluation\n",
        "import tokun.meta\n",
        "import tokun.pipeline\n",
        "import tokun.model\n",
        "\n",
        "import llaminate.model\n",
        "import llaminate.pipeline\n",
        "import llaminate.utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn1ywhSrpin9",
        "outputId": "476ac6d9-4793-4aad-d0e7-ba06ee5195fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Setup the GPU / TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFIMfPmgQa0h",
        "outputId": "ddcdd050-be54-4dd7-bbca-8119a5bed29f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 object at 0x7988ac94fa00>\n"
          ]
        }
      ],
      "source": [
        "# DEVICES #####################################################################\n",
        "\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "\n",
        "CPU = tf.config.list_logical_devices('CPU')\n",
        "GPU = tf.config.list_logical_devices('GPU')\n",
        "TPU = tf.config.list_logical_devices('TPU')\n",
        "\n",
        "if TPU:\n",
        "    RESOLVER = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(RESOLVER)\n",
        "    tf.tpu.experimental.initialize_tpu_system(RESOLVER)\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.TPUStrategy(RESOLVER)\n",
        "elif GPU:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(GPU)\n",
        "else:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(CPU)\n",
        "\n",
        "print(DISTRIBUTION_STRATEGY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9066X5EOyAX"
      },
      "source": [
        "## Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFSPMtQaO1fu"
      },
      "outputs": [],
      "source": [
        "# TOGGLE ######################################################################\n",
        "\n",
        "IMPORT = False\n",
        "FREEZE = True # freeze tokun weights\n",
        "TRAINING = True\n",
        "DEBUG = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t1jfsJlM3SX"
      },
      "source": [
        "## Defining The Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z74MlibMWnu"
      },
      "outputs": [],
      "source": [
        "# MODEL PARAMETERS ############################################################\n",
        "\n",
        "N_SEQUENCE_AXIS = 1\n",
        "N_FEATURE_AXIS = -1\n",
        "\n",
        "N_LAYERS_NUM = 16\n",
        "N_HEADS_NUM = 4\n",
        "\n",
        "N_CACHE_DIM = 256 # 2048 in llama3-8B but tokun embeddings = 16 chr = 4 llama3 tokens\n",
        "N_EMBED_DIM = 256\n",
        "N_HIDDEN_DIM = 4 * N_EMBED_DIM\n",
        "N_HEAD_DIM = N_EMBED_DIM // N_HEADS_NUM\n",
        "\n",
        "LLAMINATE_PATH = 'llaminate.keras'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGN0D5Mqv7Vi"
      },
      "outputs": [],
      "source": [
        "# TOKENIZER PARAMETERS ########################################################\n",
        "\n",
        "TOKUN_DIM = [16, 4]\n",
        "TOKUN_FACTOR = math.prod(TOKUN_DIM) // 4\n",
        "TOKUN_VERSION = tokun.meta.version(units=TOKUN_DIM, axis=1)\n",
        "\n",
        "TOKUN_LABEL = '7.7'\n",
        "TOKUN_PATH = 'tokun.keras'\n",
        "TOKUN_URL = 'https://github.com/apehex/tokun/raw/main/models/{}/{}/{}.keras'.format(*TOKUN_VERSION, TOKUN_LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2bgdk4P02n8"
      },
      "outputs": [],
      "source": [
        "# TRAINING PARAMETERS #########################################################\n",
        "\n",
        "N_BATCH_DIM = 128\n",
        "N_SAMPLE_DIM = N_CACHE_DIM * TOKUN_FACTOR\n",
        "\n",
        "N_EPOCHS = 8\n",
        "\n",
        "R_0, B_1, B_2 = (0.1 if IMPORT else 1.) * 0.001, 0.9, 0.99\n",
        "\n",
        "CLASS_WEIGHTS = {__c: 0.3 if __c == 0 else 1. for __c in range(256)} # there are 3 times more 0s than other bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm6y63XRBz07"
      },
      "outputs": [],
      "source": [
        "# DERIVED PARAMETERS ##########################################################\n",
        "\n",
        "DATETIME = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "LLAMINATE_VERSION = [str(N_LAYERS_NUM), str(N_HIDDEN_DIM)]\n",
        "LLAMINATE_LOGS_PATH = os.path.join('.logs/', *LLAMINATE_VERSION, DATETIME)\n",
        "LLAMINATE_MODEL_PATH = 'llaminate.keras'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEyFtkcFNGe4"
      },
      "source": [
        "## Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWxgap423z1a"
      },
      "outputs": [],
      "source": [
        "# META ########################################################################\n",
        "\n",
        "# TODO bigcode/the-stack\n",
        "# TODO ArmelR/stack-exchange-instruction\n",
        "\n",
        "DATASETS_META = {\n",
        "    'pt-wikipedia': {\n",
        "        'path': 'wikimedia/wikipedia',\n",
        "        'name': '20231101.en',\n",
        "        'train': 'train[:90%]',\n",
        "        'test': 'train[-10%:]',\n",
        "        'features': ['text'],},\n",
        "    'ft-retro-ascii-art': {\n",
        "        'path': 'jdpressman/retro-ascii-art-v1',\n",
        "        'name': None,\n",
        "        'train': 'train',\n",
        "        'test': 'validation',\n",
        "        'features': ['prompt', 'art_aic'],},\n",
        "    'ft-stack-exchange': {\n",
        "        'path': 'Alignment-Lab-AI/Stack-Exchange-April',\n",
        "        'name': None,\n",
        "        'train': 'train[:90%]',\n",
        "        'test': 'train[-10%:]',\n",
        "        'features': ['question', 'answer'],},\n",
        "    'ft-math': {\n",
        "        'path': 'hendrycks/competition_math',\n",
        "        'name': None,\n",
        "        'train': 'train',\n",
        "        'test': 'test',\n",
        "        'features': ['problem', 'solution'],},}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "74dee2f4e6f74ef6bd2be8e4ad0fac0f",
            "a4bdebecb4094ca0ad21d4c2ab94cb5f",
            "b576bd56349d429ebb0e513294edba4f",
            "7d73b51bf59b40ac926c58f17f73f85a",
            "283c406159d94cdc909b0364d0a06a41",
            "b8ba8062500548069781e4846b143f81",
            "f99667bd33bd40908f69e7c89dda2be6",
            "76c916dfc57b41649458cce1544068e3",
            "63e01388f4d74b31adce183ade7739b7",
            "44fea4342d7e4007bda296f774ae7904",
            "1ef48f381c3e493596ca60b631572890",
            "f1a0f74a3bc1499b8d7e88329cab8ea9",
            "d4c8e315ecc74f7180f0c178d8d41300",
            "b04e4d6e3da74331bb601fdb5b473c1c",
            "5a460fd4b49742f0b26fdc2d6256fac6",
            "3abc32e99a604935995cadaf3c173cc3",
            "8417fdcfe554414b9664d0ccef346260",
            "610872a101f24e368ee1c85c0f08727a",
            "ef4d3cba49954f3db1aef9e8a9bd5c73",
            "220794aa31954093b4c0a50e6b5249d6",
            "52968de631b1459a871ff27e92f96edb",
            "c5646e3cedae401fb6861fbee719a7ce",
            "eb1781cf3daa4ea4ad7d8fb44a588bfb",
            "a622d99e742c4d459849867ecb1b8124",
            "12c334e0613447608eca520f9397c1bb",
            "6440080e3b204ad9a4e4290c3d6b6df1",
            "a857e37d5558461887c143cc68671a63",
            "589ff32ca98e474aa7cdd78c268cc803",
            "61634757531343dc846f1830308a2ea3",
            "82b53a173d5c42aabfd4c622c817479e",
            "957ea201d16a4340aaf1c3d67bd7c4df",
            "adfcbc60d32c4dba9f85a2bea895c313",
            "8df88ac61e2b4bb49ec5ef41e43d4f8f"
          ]
        },
        "id": "39aImJwK68wr",
        "outputId": "e24676bc-a5a5-4354-e723-6295e2bf68ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74dee2f4e6f74ef6bd2be8e4ad0fac0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading dataset shards:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1a0f74a3bc1499b8d7e88329cab8ea9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb1781cf3daa4ea4ad7d8fb44a588bfb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# DOWNLOAD ####################################################################\n",
        "\n",
        "DATASETS = {\n",
        "    __name: {\n",
        "        'train': ds.load_dataset(path=__args['path'], name=__args['name'], split=__args['train']).to_tf_dataset(shuffle=True, batch_size=None),\n",
        "        'test': ds.load_dataset(path=__args['path'], name=__args['name'], split=__args['test']).to_tf_dataset(shuffle=True, batch_size=None),}\n",
        "    for __name, __args in DATASETS_META.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovWpdtkifbgg"
      },
      "source": [
        "## Checking The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10Ret-lA4Emo"
      },
      "outputs": [],
      "source": [
        "# STATS #######################################################################\n",
        "\n",
        "STATS = {__n: {'min': 0, 'max': 0, 'mean': 0} for __n in DATASETS}\n",
        "\n",
        "for __name in DATASETS:\n",
        "    # sample each dataset\n",
        "    __m = DATASETS_META[__name]\n",
        "    __b = iter(DATASETS[__name]['train'])\n",
        "    __s = [next(__b) for _ in range(128)]\n",
        "    __l = [len(tf.strings.join(inputs=[__e[__f] for __f in __m['features']], separator='\\x1d').numpy()) for __e in __s]\n",
        "    # save the stats\n",
        "    STATS[__name]['min'] = min(__l)\n",
        "    STATS[__name]['max'] = max(__l)\n",
        "    STATS[__name]['mean'] = tf.reduce_mean(__l).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6fDVKYvBl2i",
        "outputId": "63349d04-3405-4fd2-88f8-87d851d493cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pt-wikipedia': {'min': 131, 'max': 52493, 'mean': 3256}, 'ft-retro-ascii-art': {'min': 3068, 'max': 3286, 'mean': 3146}, 'ft-stack-exchange': {'min': 251, 'max': 7072, 'mean': 1539}, 'ft-math': {'min': 100, 'max': 2600, 'mean': 847}}\n"
          ]
        }
      ],
      "source": [
        "print(STATS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5__iAHh41CZH"
      },
      "outputs": [],
      "source": [
        "__b = iter(DATASETS['ft-stack-exchange']['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKfqzqJ4Anv8",
        "outputId": "af13fa34-85da-4c26-8a55-546b6276ca05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b\"Use of static methods to implement logic within a class\\n\\nI've recently caught an odd behaviour in my own coding:  At some point in the last year I began creating protected static methods to implement the logic of my public methods, ensuring that the protected static version contains all of the logic, but is not affected by state.\\ne.g.\\nclass Demo\\n{\\n    string someAttribute;\\n    public Demo(string someAttribute)\\n    {\\n        this.someAttribute = someAttribute;\\n    }\\n\\n    // public method only calls the static method, passing all \\n    // parameters sent to the public function as well as any \\n    // of the object's attributes required by the function.\\n    public string AppendSomeAttribute(string textToAppendTo) =>\\n        AppendSomeAttribute(textToAppendTo, someAttribute);\\n\\n    // static method is not publicly exposed.  It contains all \\n    // of the function's logic, but is not affected by state\\n    protected static string AppendSomeAttribute(string textToAppendTo, string someAttribute) =>\\n        string.Concat(textToAppendTo, someAttribute);\\n\\n    /*\\n    // this is what a normal person would do:\\n    public string AppendSomeAttribute(string textToAppendTo) =>\\n        string.Concat(textToAppendTo, someAttribute);\\n    */\\n}\\n\\nI can't recall reading anything that would have triggered this change.  My best guess is I read something advising it which stuck in my subconscious; but it may just be a bad habit I'd unconsciously picked up.\\nTrying to work out why this may be advised I came up with the following:\\n\\nAll logic is handled in a single place; so where there are multiple public methods taking different parameters this helps keep all logic in one routine (definitely makes sense where the version of that routine which supplies all parameters is not supposed to be publicly exposed; otherwise I can't see a benefit).\\nBy removing the object's state from the equation the logic of these methods is more easily tested / proven; either by unit tests, or when copy-pasting code to LinqPad (or similar) to try it out in a sandbox.\\n\\nHowever, those aren't great justifications for doing this as a de-facto coding style (i.e. where there isn't a specific scenario to justify this, such as the many public overloads of the same method with none taking all parameters example, as outlined above).\\nQuestion:\\nIs there any clear benefit to writing code in this way?\\n\\n\\n\\x1dThe main use case (according to your own explanation) is to avoid using instance values. But I see no reason to keep the method as static after it is developed. \\n\\nDevelop a (non-static) method\\nPut it to static to see if any errors pop up in the method body, which indicates you're using instance values.\\nRemove the static. \\n\\nI'm all for clever methods to factcheck something, but I see no reason to persist your clever-but-unusual approach after you've confirmed what you wanted to. \\nAs a secondary argument, if you already can't keep track of the values used in a method, the method is probably handling too much to begin with.\\n\\n\\nBy removing the object's state from the equation the logic of these methods is more easily tested / proven; either by unit tests,\\n\\nI'm not quite following here. Static methods (by themselves) are notoriously hard to unit test because it's not easy to mock a state.\\nA static wrapped in a non-static is no different from an allround non-static setup; in terms of unit testing.\\n\\n\\nAll logic is handled in a single place; so where there are multiple public methods taking different parameters this helps keep all logic in one routine  (definitely makes sense where the version of that routine which supplies all parameters is not supposed to be publicly exposed; otherwise I can't see a benefit).\\n\\nThis is an argument for public/protected/private, not static/instance. You can achieve the exact same goal with protected/private instance methods.\\n\\nI simply don't quite see the point of your code. Nothing changes if you remove the static keyword from your example.\\nIn your code comments, you say that [protected] static method is not publicly exposed, which is a mislabeling. It's not publicly exposed because it is protected, regardless of whether it's static or not.\\nIf you're talking about how a static method is not exposed on an instance; that is partially true. But that is an argument about avoiding developer error, not logical correctness.\\nFurthermore: a protected static is still publicly available inside its class and all classes that derive from it. It's not available as this.MyStaticMethod(), but it is still available as MyStaticMethod(). You're not completely circumventing its availability.\\nWhat you say isn't wrong, but I see no argument that justifies this additional level of abstraction.\\n\">"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "__s = next(__b)\n",
        "tf.strings.join(inputs=[__s['question'], __s['answer']], separator='\\x1d')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cheN52OEchs"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCMihca3F2yQ"
      },
      "outputs": [],
      "source": [
        "# ITERATE #####################################################################\n",
        "\n",
        "for __name in DATASETS:\n",
        "    DATASETS[__name]['train'] = llaminate.pipeline.preprocess(dataset=DATASETS[__name]['train'], token_dim=math.prod(TOKUN_DIM), embed_dim=N_EMBED_DIM, sample_dim=N_SAMPLE_DIM, features=DATASETS_META[__name]['features'])\n",
        "    DATASETS[__name]['test'] = llaminate.pipeline.preprocess(dataset=DATASETS[__name]['test'], token_dim=math.prod(TOKUN_DIM), embed_dim=N_EMBED_DIM, sample_dim=N_SAMPLE_DIM, features=DATASETS_META[__name]['features'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxz2uQx-g5SR"
      },
      "outputs": [],
      "source": [
        "# CONCATENATE #################################################################\n",
        "\n",
        "DATASET_TRAIN = functools.reduce(lambda __l, __r: __l.concatenate(__r), [DATASETS[__n]['train'] for __n in (set(DATASETS.keys()) - {'ft-retro-ascii-art'})]) # - {'pt-wikipedia'}\n",
        "DATASET_TEST = functools.reduce(lambda __l, __r: __l.concatenate(__r), [DATASETS[__n]['test'] for __n in (set(DATASETS.keys()) - {'ft-retro-ascii-art'})]) # - {'pt-wikipedia'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJFgVaASv0bY",
        "outputId": "4d563a89-87ac-4ba4-c35d-ab2ce6e9e905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(16384,), dtype=tf.uint8, name=None), TensorSpec(shape=(16384, 256), dtype=tf.float32, name=None))\n",
            "(TensorSpec(shape=(16384,), dtype=tf.uint8, name=None), TensorSpec(shape=(16384, 256), dtype=tf.float32, name=None))\n"
          ]
        }
      ],
      "source": [
        "# CHECK DATASET ###############################################################\n",
        "\n",
        "print(DATASET_TRAIN.element_spec)\n",
        "print(DATASET_TEST.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RyKbfSgZOrB",
        "outputId": "0996faf8-b51b-4e26-9679-86924fbb950c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 9,431,038 samples\n",
            "test:  1,052,059 samples\n"
          ]
        }
      ],
      "source": [
        "print('train: {:,} samples'.format(DATASET_TRAIN.cardinality().numpy()))\n",
        "print('test:  {:,} samples'.format(DATASET_TEST.cardinality().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFehgkiDwBI2"
      },
      "source": [
        "## Downloading The Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfIZb86Fg0dQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67feea0-d6b3-44eb-8ab9-25a02147dce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokun.keras', <http.client.HTTPMessage at 0x797ed43487f0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# IMPORT ######################################################################\n",
        "\n",
        "urllib.request.urlretrieve(TOKUN_URL, TOKUN_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39n2JmXG6yv"
      },
      "source": [
        "## Initializing The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "130LK_GQv9X9"
      },
      "outputs": [],
      "source": [
        "# DEBUG MODEL #################################################################\n",
        "\n",
        "class DebugModel(tf.keras.Sequential):\n",
        "    def __init__(self, **kwargs) -> None:\n",
        "        super(DebugModel, self).__init__(\n",
        "            layers=[\n",
        "                tf.keras.layers.Embedding(\n",
        "                    input_dim=N_EMBED_DIM,\n",
        "                    output_dim=N_EMBED_DIM,\n",
        "                    embeddings_initializer='glorot_uniform',\n",
        "                    name='embed-1')])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OVERALL SCOPE ###############################################################\n",
        "\n",
        "with DISTRIBUTION_STRATEGY.scope():\n",
        "    # TOKENIZER ###############################################################\n",
        "    TOKUN = tf.keras.models.load_model(TOKUN_PATH, compile=False)\n",
        "    TOKUN.trainable = not FREEZE # freeze the weights\n",
        "    # TOKUN.compile(\n",
        "    #     optimizer=tf.keras.optimizers.Adam(learning_rate=R_MAX),\n",
        "    #     loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0., axis=-1, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name='loss'),\n",
        "    #     metrics=[byte_accuracy, character_accuracy, token_accuracy])\n",
        "\n",
        "    # METRICS #################################################################\n",
        "    byte_accuracy = mlable.metrics.CategoricalGroupAccuracy(group=1, name='byte_accuracy')\n",
        "    character_accuracy = mlable.metrics.CategoricalGroupAccuracy(group=4, name='character_accuracy')\n",
        "    token_accuracy = mlable.metrics.CategoricalGroupAccuracy(group=math.prod(TOKUN_DIM), name='token_accuracy')\n",
        "\n",
        "    # WEIGHTS #################################################################\n",
        "    if IMPORT and os.path.isfile(LLAMINATE_MODEL_PATH):\n",
        "        LLAMINATE = tf.keras.models.load_model(LLAMINATE_MODEL_PATH, compile=False)\n",
        "    else:\n",
        "        LLAMINATE = llaminate.model.Transformer(num_layers=N_LAYERS_NUM, num_heads=N_HEADS_NUM, cache_dim=N_CACHE_DIM, embed_dim=N_EMBED_DIM, head_dim=N_HEAD_DIM, hidden_dim=N_HIDDEN_DIM)\n",
        "\n",
        "    # INIT ####################################################################\n",
        "    LLAMINATE.set_tokenizer(encoder=TOKUN._encoder, decoder=TOKUN._decoder)\n",
        "    # simpler model to debug\n",
        "    if DEBUG: LLAMINATE = DebugModel()\n",
        "\n",
        "    # INPUT ###################################################################\n",
        "    # __input = tf.keras.Input(shape=(4 * TOKUN_FACTOR * N_CACHE_DIM,), batch_size=N_BATCH_DIM)\n",
        "    # LLAMINATE = tf.keras.models.Model(__input, LLAMINATE(__input))\n",
        "\n",
        "    # COMPILE #################################################################\n",
        "    LLAMINATE.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=R_0, beta_1=B_1, beta_2=B_2),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0., axis=-1, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name='loss'),\n",
        "        metrics=[byte_accuracy, character_accuracy, token_accuracy])"
      ],
      "metadata": {
        "id": "AzD3vE7ZlB-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLQ0A3mAiVQ7"
      },
      "outputs": [],
      "source": [
        "__b = iter(DATASET_TEST.batch(N_BATCH_DIM))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O08Up69-i5DL",
        "outputId": "d4818d0c-ebd0-478a-eb06-2df880e54618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 16384)\n",
            "(128, 256, 256)\n",
            "(128, 16384, 256)\n"
          ]
        }
      ],
      "source": [
        "__x, __y = next(__b)\n",
        "print(__x.shape)\n",
        "print(LLAMINATE._encoder(__x, training=True).shape)\n",
        "print(LLAMINATE(__x, training=True).shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOKUN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBBF4QpNVHtF",
        "outputId": "aec2796d-3493-497e-9fc3-00c89345b5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"auto_encoder_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  1377792   \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  1382656   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2760448 (10.53 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 2760448 (10.53 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz1lRnWtMSUm",
        "outputId": "ca54ce52-008c-407a-dc5e-6be75bacf619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block-0 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-1 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-2 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-3 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-4 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-5 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-6 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-7 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-8 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-9 (DecoderBlock)      multiple                  1049600   \n",
            "                                                                 \n",
            " block-10 (DecoderBlock)     multiple                  1049600   \n",
            "                                                                 \n",
            " block-11 (DecoderBlock)     multiple                  1049600   \n",
            "                                                                 \n",
            " block-12 (DecoderBlock)     multiple                  1049600   \n",
            "                                                                 \n",
            " block-13 (DecoderBlock)     multiple                  1049600   \n",
            "                                                                 \n",
            " block-14 (DecoderBlock)     multiple                  1049600   \n",
            "                                                                 \n",
            " block-15 (DecoderBlock)     multiple                  1049600   \n",
            "                                                                 \n",
            " layer_normalization_65 (La  multiple                  512       \n",
            " yerNormalization)                                               \n",
            "                                                                 \n",
            " encoder_1 (Encoder)         multiple                  1377792   \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  1382656   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19554560 (74.59 MB)\n",
            "Trainable params: 16794112 (64.06 MB)\n",
            "Non-trainable params: 2760448 (10.53 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LLAMINATE.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRkNkXthBwar"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "beTpALmzFdu1",
        "outputId": "9f707895-b5f9-4260-9e3e-7d41a6b1fa5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 1/8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\", line 145, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1124, in add_variable_from_reference\n        with strategy.extended.colocate_vars_with(model_variable):\n\n    AttributeError: 'NoneType' object has no attribute 'extended'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a6856b990c7b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtb_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLAMINATE_LOGS_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# model fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         TRAINING_HISTORY = LLAMINATE.fit(\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATASETS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft-stack-exchange'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_BATCH_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 638, in apply_gradients\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\", line 145, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 1124, in add_variable_from_reference\n        with strategy.extended.colocate_vars_with(model_variable):\n\n    AttributeError: 'NoneType' object has no attribute 'extended'\n"
          ]
        }
      ],
      "source": [
        "# TRAIN #######################################################################\n",
        "\n",
        "if TRAINING:\n",
        "    with DISTRIBUTION_STRATEGY.scope():\n",
        "        # callbacks\n",
        "        lr_callback = tf.keras.callbacks.LearningRateScheduler(functools.partial(mlable.optimizers.learning_rate_hokusai, lr_min=R_MIN, lr_max=R_MAX, lr_exp=R_EXP, rampup=N_EPOCHS_RAMPUP, sustain=N_EPOCHS_SUSTAIN), verbose=True)\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(LLAMINATE_MODEL_PATH, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "        tb_callback = tf.keras.callbacks.TensorBoard(log_dir=LLAMINATE_LOGS_PATH)\n",
        "        # model fitting\n",
        "        TRAINING_HISTORY = LLAMINATE.fit(\n",
        "            x=DATASETS['ft-stack-exchange']['train'].batch(N_BATCH_DIM).prefetch(1),\n",
        "            batch_size=None,\n",
        "            epochs=N_EPOCHS,\n",
        "            validation_split=None,\n",
        "            validation_data=DATASETS['ft-stack-exchange']['test'].batch(N_BATCH_DIM).prefetch(1),\n",
        "            validation_freq=list(range(1, N_EPOCHS + 1, 1)),\n",
        "            class_weight=CLASS_WEIGHTS,\n",
        "            verbose=1,\n",
        "            callbacks=[lr_callback, cp_callback, tb_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMqMBhAidTZ9"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHtROW1K1R7c"
      },
      "source": [
        "## Dataviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiRVgG-oSfb7"
      },
      "outputs": [],
      "source": [
        "# DATA ########################################################################\n",
        "\n",
        "SAMPLES = [\n",
        "    \"\"\",   .\\nt-  (t-SNE)         , 2002  Sam Rowise    .[1] t-SNE    ,    2, 3     .  t-SNE    2, 3 ,      .\"\"\",\n",
        "    \"\"\"class Encoder(tf.keras.models.Model):\\n    def __init__(self, depth: int, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, attention: bool=False, **kwargs) -> None:\\n        super(Encoder, self).__init__(**kwargs)\\n        self._encoder = tf.keras.Sequential([\\n            tf.keras.Input(shape=(encoding_dim,), batch_size=batch_dim, name='input'), # (B * G ^ D, U)\\n            tf.keras.layers.Dense(units=embedding_dim, activation=None, use_bias=False, kernel_initializer='glorot_uniform', bias_initializer=None, name='embed-1'),] # (B * G ^ D, U) => (B * G ^ D, E)\\n            + [tokun.layers.TokenizeBlock(left_axis=-2, right_axis=-1, token_dim=token_dim, latent_dim=latent_dim, attention=attention, name='tokenize' + (__i + 1) * '-4') for __i in range(depth)]) # (B * G ^ i, E) => (B * G ^ (i-1), E)\\n\\n    def call(self, x: tf.Tensor) -> tf.Tensor:\\n        return self._encoder(x)\\n\"\"\",\n",
        "    \"\"\"class AutoEncoder(tf.keras.models.Model):\\n    def __init__(self, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, **kwargs) -> None:\\n        super(AutoEncoder, self).__init__(**kwargs)\\n        self._encoder = Encoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n        self._decoder = Decoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n\\n    def call(self, x: tf.Tensor) -> tf.Tensor:\\n        return self._decoder(self._encoder(x))\"\"\",\n",
        "    \"\"\"class AutoEncoder(tf.keras.models.Model):\\n  def __init__(self, token_dim: int, encoding_dim: int, embedding_dim: int, latent_dim: int, batch_dim: int=None, **kwargs) -> None:\\n    super(AutoEncoder, self).__init__(**kwargs)\\n    self._encoder = Encoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n    self._decoder = Decoder(token_dim=token_dim, encoding_dim=encoding_dim, embedding_dim=embedding_dim, latent_dim=latent_dim, batch_dim=batch_dim)\\n\\n  def call(self, x: tf.Tensor) -> tf.Tensor:\\n    return self._decoder(self._encoder(x))\"\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8naQsR7i8iea"
      },
      "outputs": [],
      "source": [
        "# CACHE #######################################################################\n",
        "\n",
        "__cache = llaminate.utils.create_cache(batch_dim=N_BATCH_DIM, cache_dim=N_CACHE_DIM, head_dim=N_HEAD_DIM, num_layers=N_LAYERS_NUM, num_heads=N_HEADS_NUM)\n",
        "__step = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HubWVf_L_Frh"
      },
      "outputs": [],
      "source": [
        "# PREPROCESS ##################################################################\n",
        "\n",
        "__prompt = \"\"\"Skynet is an artificial neural network-based conscious group mind and artificial general superintelligence system that serves as the antagonistic force of the Terminator franchise.\"\"\"\n",
        "__inputs = tokun.pipeline.preprocess(text=__prompt, groups=TOKUN_DIM, expand=N_SEQUENCE_AXIS * [1], flatten=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt7OdZw22vGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "107eb020-c601-41ac-80e7-83a6f29d7263"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 16384), found shape=(1, 768)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-fa5755c7936d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# PREDICT #####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m__predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLLAMINATE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtokun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    299\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 16384), found shape=(1, 768)"
          ]
        }
      ],
      "source": [
        "# PREDICT #####################################################################\n",
        "\n",
        "__predictions, _ = LLAMINATE(inputs=__inputs, cache=None, position=0, training=False, mask=None)\n",
        "tokun.pipeline.postprocess(__predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm0qRLA9r7zL"
      },
      "outputs": [],
      "source": [
        "__batch = iter(DATASET_TRAIN.batch(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzM21G9YsIT7"
      },
      "outputs": [],
      "source": [
        "__x, __y = next(__batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R77elVHVsPXr"
      },
      "outputs": [],
      "source": [
        "__p = LLAMINATE(inputs=__x, cache=None, position=0, training=True, mask=None)\n",
        "\n",
        "__xt = tokun.pipeline.postprocess(tf.one_hot(__x, depth=256))\n",
        "__yt = tokun.pipeline.postprocess(__y)\n",
        "__yp = tokun.pipeline.postprocess(__p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkpSSNd8mhRz"
      },
      "outputs": [],
      "source": [
        "print(tokun.evaluation.compare(__yt, __yp))\n",
        "print(__yt)\n",
        "print(__yp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWmXaJzjhPaR"
      },
      "outputs": [],
      "source": [
        "tf.argmax(LLAMINATE._decoder(LLAMINATE._encoder(__x[:, :128])), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPRq7KOzkAly"
      },
      "outputs": [],
      "source": [
        "__x[:, :128]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgt0SQDbaopC"
      },
      "source": [
        "## Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eJmv4xjnTH4t"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir .logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74dee2f4e6f74ef6bd2be8e4ad0fac0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4bdebecb4094ca0ad21d4c2ab94cb5f",
              "IPY_MODEL_b576bd56349d429ebb0e513294edba4f",
              "IPY_MODEL_7d73b51bf59b40ac926c58f17f73f85a"
            ],
            "layout": "IPY_MODEL_283c406159d94cdc909b0364d0a06a41"
          }
        },
        "a4bdebecb4094ca0ad21d4c2ab94cb5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ba8062500548069781e4846b143f81",
            "placeholder": "",
            "style": "IPY_MODEL_f99667bd33bd40908f69e7c89dda2be6",
            "value": "Resolvingdatafiles:100%"
          }
        },
        "b576bd56349d429ebb0e513294edba4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76c916dfc57b41649458cce1544068e3",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63e01388f4d74b31adce183ade7739b7",
            "value": 41
          }
        },
        "7d73b51bf59b40ac926c58f17f73f85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44fea4342d7e4007bda296f774ae7904",
            "placeholder": "",
            "style": "IPY_MODEL_1ef48f381c3e493596ca60b631572890",
            "value": "41/41[00:00&lt;00:00,49.46it/s]"
          }
        },
        "283c406159d94cdc909b0364d0a06a41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8ba8062500548069781e4846b143f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99667bd33bd40908f69e7c89dda2be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76c916dfc57b41649458cce1544068e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e01388f4d74b31adce183ade7739b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44fea4342d7e4007bda296f774ae7904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef48f381c3e493596ca60b631572890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1a0f74a3bc1499b8d7e88329cab8ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4c8e315ecc74f7180f0c178d8d41300",
              "IPY_MODEL_b04e4d6e3da74331bb601fdb5b473c1c",
              "IPY_MODEL_5a460fd4b49742f0b26fdc2d6256fac6"
            ],
            "layout": "IPY_MODEL_3abc32e99a604935995cadaf3c173cc3"
          }
        },
        "d4c8e315ecc74f7180f0c178d8d41300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8417fdcfe554414b9664d0ccef346260",
            "placeholder": "",
            "style": "IPY_MODEL_610872a101f24e368ee1c85c0f08727a",
            "value": "Loadingdatasetshards:100%"
          }
        },
        "b04e4d6e3da74331bb601fdb5b473c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef4d3cba49954f3db1aef9e8a9bd5c73",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_220794aa31954093b4c0a50e6b5249d6",
            "value": 33
          }
        },
        "5a460fd4b49742f0b26fdc2d6256fac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52968de631b1459a871ff27e92f96edb",
            "placeholder": "",
            "style": "IPY_MODEL_c5646e3cedae401fb6861fbee719a7ce",
            "value": "33/33[00:00&lt;00:00,414.39it/s]"
          }
        },
        "3abc32e99a604935995cadaf3c173cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8417fdcfe554414b9664d0ccef346260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610872a101f24e368ee1c85c0f08727a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef4d3cba49954f3db1aef9e8a9bd5c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220794aa31954093b4c0a50e6b5249d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52968de631b1459a871ff27e92f96edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5646e3cedae401fb6861fbee719a7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb1781cf3daa4ea4ad7d8fb44a588bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a622d99e742c4d459849867ecb1b8124",
              "IPY_MODEL_12c334e0613447608eca520f9397c1bb",
              "IPY_MODEL_6440080e3b204ad9a4e4290c3d6b6df1"
            ],
            "layout": "IPY_MODEL_a857e37d5558461887c143cc68671a63"
          }
        },
        "a622d99e742c4d459849867ecb1b8124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589ff32ca98e474aa7cdd78c268cc803",
            "placeholder": "",
            "style": "IPY_MODEL_61634757531343dc846f1830308a2ea3",
            "value": "Resolvingdatafiles:100%"
          }
        },
        "12c334e0613447608eca520f9397c1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b53a173d5c42aabfd4c622c817479e",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_957ea201d16a4340aaf1c3d67bd7c4df",
            "value": 41
          }
        },
        "6440080e3b204ad9a4e4290c3d6b6df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adfcbc60d32c4dba9f85a2bea895c313",
            "placeholder": "",
            "style": "IPY_MODEL_8df88ac61e2b4bb49ec5ef41e43d4f8f",
            "value": "41/41[00:00&lt;00:00,95.26it/s]"
          }
        },
        "a857e37d5558461887c143cc68671a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "589ff32ca98e474aa7cdd78c268cc803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61634757531343dc846f1830308a2ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b53a173d5c42aabfd4c622c817479e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957ea201d16a4340aaf1c3d67bd7c4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adfcbc60d32c4dba9f85a2bea895c313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df88ac61e2b4bb49ec5ef41e43d4f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}